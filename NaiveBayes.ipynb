{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0\n[3.393533211, 2.331273381, 0]\n[3.110073483, 1.781539638, 0]\n[1.343808831, 3.368360954, 0]\n[3.582294042, 4.67917911, 0]\n[2.280362439, 2.866990263, 0]\n1\n[7.423436942, 4.696522875, 1]\n[5.745051997, 3.533989803, 1]\n[9.172168622, 2.511101045, 1]\n[7.792783481, 3.424088941, 1]\n[7.939820817, 0.791637231, 1]\n"}],"source":"def separate_byClass(dataset):\n    separated =  {}\n    for i in range(len(dataset)):\n        vector  = dataset[i]\n        class_value = vector[-1]\n        if(class_value not in separated.keys() ):\n            separated[class_value]=[]\n             \n        separated[class_value].append(vector)\n    return separated\n\n\n'''checking function'''\ndataset = [[3.393533211,2.331273381,0],\n\t[3.110073483,1.781539638,0],\n\t[1.343808831,3.368360954,0],\n\t[3.582294042,4.67917911,0],\n\t[2.280362439,2.866990263,0],\n\t[7.423436942,4.696522875,1],\n\t[5.745051997,3.533989803,1],\n\t[9.172168622,2.511101045,1],\n\t[7.792783481,3.424088941,1],\n\t[7.939820817,0.791637231,1]]\nseparated = separate_byClass(dataset)\n# separated =\n# {0: [[3.393533211, 2.331273381, 0],\n#   [3.110073483, 1.781539638, 0],\n#   [1.343808831, 3.368360954, 0],\n#   [3.582294042, 4.67917911, 0],\n#   [2.280362439, 2.866990263, 0]],\n#  1: [[7.423436942, 4.696522875, 1],\n#   [5.745051997, 3.533989803, 1],\n#   [9.172168622, 2.511101045, 1],\n#   [7.792783481, 3.424088941, 1],\n#   [7.939820817, 0.791637231, 1]]}\nfor label in separated:\n\tprint(label)\n\tfor row in separated[label]:\n\t\tprint(row)\n"},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":"\n# Calculating the mean of a list of numbers\ndef mean(numbers):\n\treturn sum(numbers)/float(len(numbers))\n\nfrom math import sqrt\n \n# Calculating the standard deviation of a list of numbers\ndef stdev(numbers):\n\tavg = mean(numbers)\n\tvariance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n\treturn sqrt(variance)"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"[(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]\n"}],"source":"'''We pass in the dataset to the zip() function with the * operator that separates the dataset (that is a list of lists) into separate lists for each row. The zip() function then iterates over each element of each row and returns a column from the dataset as a list of numbers'''\n\ndef summary(dataset):\n    summaries = [(mean(column),\n                 stdev(column),\n                 len(column))  \n                 for column in zip(*dataset)]\n    del(summaries[-1])\n    return summaries\ndataset = [[3.393533211,2.331273381,0],\n\t[3.110073483,1.781539638,0],\n\t[1.343808831,3.368360954,0],\n\t[3.582294042,4.67917911,0],\n\t[2.280362439,2.866990263,0],\n\t[7.423436942,4.696522875,1],\n\t[5.745051997,3.533989803,1],\n\t[9.172168622,2.511101045,1],\n\t[7.792783481,3.424088941,1],\n\t[7.939820817,0.791637231,1]]\nprint(summary(dataset))\n# summaries =\n# [(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0\n(2.7420144012, 0.9265683289298018, 5)\n(3.0054686692, 1.1073295894898725, 5)\n1\n(7.6146523718, 1.2344321550313704, 5)\n(2.9914679790000003, 1.4541931384601618, 5)\n"}],"source":"def summarize_by_class(dataset):\n\tseparated = separate_byClass(dataset)\n\tsummaries = dict()\n\tfor class_value, rows in separated.items():\n\t\tsummaries[class_value] = summary(rows)\n\treturn summaries\n\ndataset = [[3.393533211,2.331273381,0],\n\t[3.110073483,1.781539638,0],\n\t[1.343808831,3.368360954,0],\n\t[3.582294042,4.67917911,0],\n\t[2.280362439,2.866990263,0],\n\t[7.423436942,4.696522875,1],\n\t[5.745051997,3.533989803,1],\n\t[9.172168622,2.511101045,1],\n\t[7.792783481,3.424088941,1],\n\t[7.939820817,0.791637231,1]]\ns = summarize_by_class(dataset)\n#   \n# s={0: [(2.7420144012, 0.9265683289298018, 5),\n#   (3.0054686692, 1.1073295894898725, 5)],\n#  1: [(7.6146523718, 1.2344321550313704, 5),\n#   (2.9914679790000003, 1.4541931384601618, 5)]}\nfor label in s:\n\tprint(label)\n\tfor row in s[label]:\n\t\tprint(row)\n"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"from math import exp\ndef gaussianPDF(x,mean,stdev):\n    exponent = exp(-((x-mean)**2 / (2 * stdev**2 )))\n    return (1 / (sqrt(2 * pi) * stdev)) * exponent\n"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"{0: 0.05032427673372076, 1: 0.00011557718379945765}\n"}],"source":"from math import pi\ndef class_probability(summaries,row):\n\n    total_rows =  sum([summaries[label][0][2] for label in summaries])\n    probabilities = dict()\n    for class_value,class_summaries in summaries.items():\n\n        probabilities[class_value]=summaries[class_value][0][2]/float(total_rows)\n        for i in range(len(class_summaries)):\n            mean,stdev,count = class_summaries[i]\n            probabilities[class_value]*=gaussianPDF(row[i],mean,stdev)\n    return probabilities\ndataset = [[3.393533211,2.331273381,0],\n\t[3.110073483,1.781539638,0],\n\t[1.343808831,3.368360954,0],\n\t[3.582294042,4.67917911,0],\n\t[2.280362439,2.866990263,0],\n\t[7.423436942,4.696522875,1],\n\t[5.745051997,3.533989803,1],\n\t[9.172168622,2.511101045,1],\n\t[7.792783481,3.424088941,1],\n\t[7.939820817,0.791637231,1]]\n\nsummaries = summarize_by_class(dataset)\nprobabilities = class_probability(summaries, dataset[0])\nprint(probabilities)\n#{0: 0.05032427673372076, 1: 0.00011557718379945765}"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":"'''Applying to iris dataset'''\nfrom csv import reader\nfrom random import seed\nfrom random import randrange\nfrom math import sqrt,exp,pi\n\ndef load_csv(filename):\n\tdataset = list()\n\twith open(filename, 'rt') as file:\n\t\tcsv_reader = reader(file)\n\t\tfor row in csv_reader:\n\t\t\tif not row:\n\t\t\t\tcontinue\n\t\t\tdataset.append(row)\n\treturn dataset\ndef str_column_to_float(dataset, column):\n\tfor row in dataset:\n\t\trow[column] = float(row[column].strip())\ndef str_column_to_int(dataset, column):\n\tclass_values = [row[column] for row in dataset]\n\tunique = set(class_values)\n\tlookup = dict()\n\tfor i, value in enumerate(unique):\n\t\tlookup[value] = i\n\tfor row in dataset:\n\t\trow[column] = lookup[row[column]]\n\treturn lookup\n\ndef cross_validation_split(dataset, n_folds):\n\tdataset_split = list()\n\tdataset_copy = list(dataset)\n\tfold_size = int(len(dataset) / n_folds)\n\tfor _ in range(n_folds):\n\t\tfold = list()\n\t\twhile len(fold) < fold_size:\n\t\t\tindex = randrange(len(dataset_copy))\n\t\t\tfold.append(dataset_copy.pop(index))\n\t\tdataset_split.append(fold)\n\treturn dataset_split\n\ndef accuracy_metric(actual, predicted):\n\tcorrect = 0\n\tfor i in range(len(actual)):\n\t\tif actual[i] == predicted[i]:\n\t\t\tcorrect += 1\n\treturn correct / float(len(actual)) * 100.0\n\ndef evaluate_algorithm(dataset, algorithm, n_folds, *args):\n\tfolds = cross_validation_split(dataset, n_folds)\n\tscores = list()\n\tfor fold in folds:\n\t\ttrain_set = list(folds)\n\t\ttrain_set.remove(fold)\n\t\ttrain_set = sum(train_set, [])\n\t\ttest_set = list()\n\t\tfor row in fold:\n\t\t\trow_copy = list(row)\n\t\t\ttest_set.append(row_copy)\n\t\t\trow_copy[-1] = None\n\t\tpredicted = algorithm(train_set, test_set, *args)\n\t\tactual = [row[-1] for row in fold]\n\t\taccuracy = accuracy_metric(actual, predicted)\n\t\tscores.append(accuracy)\n\treturn scores\n\ndef predict(summaries, row):\n\tprobabilities = class_probability(summaries, row)\n\tbest_label, best_prob = None, -1\n\tfor class_value, probability in probabilities.items():\n\t\tif best_label is None or probability > best_prob:\n\t\t\tbest_prob = probability\n\t\t\tbest_label = class_value\n\treturn best_label\n\ndef naive_bayes(train, test):\n\tsummarize = summarize_by_class(train)\n\tpredictions = list()\n\tfor row in test:\n\t\toutput = predict(summarize, row)\n\t\tpredictions.append(output)\n\treturn(predictions)\n"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Scores: [93.33333333333333, 96.66666666666667, 100.0, 93.33333333333333, 93.33333333333333]\nMean Accuracy: 95.333%\n"}],"source":"seed(1)\nfilename = 'Data\\iris.data'\ndataset = load_csv(filename)\nfor i in range(len(dataset[0])-1):\n\tstr_column_to_float(dataset, i)\n# convert class column to integers\nstr_column_to_int(dataset, len(dataset[0])-1)\n# evaluate algorithm\nn_folds = 5\nscores = evaluate_algorithm(dataset, naive_bayes, n_folds)\nprint('Scores: %s' % scores)\nprint('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n\n\n"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Data=[5.7, 2.9, 4.2, 1.3], Predicted: 2\n"}],"source":"# fit model\nmodel = summarize_by_class(dataset)\n# define a new record\nrow = [5.7,2.9,4.2,1.3]\n# predict the label\nlabel = predict(model, row)\nprint('Data=%s, Predicted: %s' % (row, label))"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}